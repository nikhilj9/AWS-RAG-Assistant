{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053256a4-7d10-4c6c-b36d-d3fa94122616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36240f5e-fec3-4db8-a337-3b498364d5d8",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f1414e-42a4-4ac9-96dc-ea5ad4f0b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/AWSBedrockRAG.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19e6546d-5f37-4d7c-b0dd-1259f0a4029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>service</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Foundation model (FM)</td>\n",
       "      <td>An AI model with a large number of parameters ...</td>\n",
       "      <td>[foundation model, FM, AI model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Base model</td>\n",
       "      <td>A foundation model that is packaged by a provi...</td>\n",
       "      <td>[base model, foundation model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Model inference</td>\n",
       "      <td>The process of a foundation model generating a...</td>\n",
       "      <td>[model inference, inference, response generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Prompt</td>\n",
       "      <td>An input provided to a model to guide it to ge...</td>\n",
       "      <td>[prompt, input, text prompt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Inference parameters</td>\n",
       "      <td>Values that can be adjusted during model infer...</td>\n",
       "      <td>[inference parameters, model control]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Batch Inference</td>\n",
       "      <td>Monitoring Token Usage and Cost</td>\n",
       "      <td>To effectively monitor token usage and associa...</td>\n",
       "      <td>[monitoring, usage, cost, token counts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Batch Inference</td>\n",
       "      <td>Token Counting Support Across Models and Regions</td>\n",
       "      <td>Token counting is a feature supported by all m...</td>\n",
       "      <td>[supported models, regions, token counting, av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Batch Inference</td>\n",
       "      <td>Retrieving Token Counts from Model Responses</td>\n",
       "      <td>When you interact with Amazon Bedrock models, ...</td>\n",
       "      <td>[token count, API response, input tokens, outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Batch Inference</td>\n",
       "      <td>Example: Retrieving Token Counts with Python S...</td>\n",
       "      <td>You can retrieve token counts using the AWS SD...</td>\n",
       "      <td>[example, python, boto3, API]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>Amazon Bedrock</td>\n",
       "      <td>Batch Inference</td>\n",
       "      <td>Requesting Quota Increases</td>\n",
       "      <td>If your generative AI application requires hig...</td>\n",
       "      <td>[quota increase, limits, service quotas, request]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         service         category  \\\n",
       "0      0  Amazon Bedrock      Terminology   \n",
       "1      1  Amazon Bedrock      Terminology   \n",
       "2      2  Amazon Bedrock      Terminology   \n",
       "3      3  Amazon Bedrock      Terminology   \n",
       "4      4  Amazon Bedrock      Terminology   \n",
       "..   ...             ...              ...   \n",
       "643  643  Amazon Bedrock  Batch Inference   \n",
       "644  644  Amazon Bedrock  Batch Inference   \n",
       "645  645  Amazon Bedrock  Batch Inference   \n",
       "646  646  Amazon Bedrock  Batch Inference   \n",
       "647  647  Amazon Bedrock  Batch Inference   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                Foundation model (FM)   \n",
       "1                                           Base model   \n",
       "2                                      Model inference   \n",
       "3                                               Prompt   \n",
       "4                                 Inference parameters   \n",
       "..                                                 ...   \n",
       "643                    Monitoring Token Usage and Cost   \n",
       "644   Token Counting Support Across Models and Regions   \n",
       "645       Retrieving Token Counts from Model Responses   \n",
       "646  Example: Retrieving Token Counts with Python S...   \n",
       "647                         Requesting Quota Increases   \n",
       "\n",
       "                                               content  \\\n",
       "0    An AI model with a large number of parameters ...   \n",
       "1    A foundation model that is packaged by a provi...   \n",
       "2    The process of a foundation model generating a...   \n",
       "3    An input provided to a model to guide it to ge...   \n",
       "4    Values that can be adjusted during model infer...   \n",
       "..                                                 ...   \n",
       "643  To effectively monitor token usage and associa...   \n",
       "644  Token counting is a feature supported by all m...   \n",
       "645  When you interact with Amazon Bedrock models, ...   \n",
       "646  You can retrieve token counts using the AWS SD...   \n",
       "647  If your generative AI application requires hig...   \n",
       "\n",
       "                                                  tags  \n",
       "0                     [foundation model, FM, AI model]  \n",
       "1                       [base model, foundation model]  \n",
       "2    [model inference, inference, response generation]  \n",
       "3                         [prompt, input, text prompt]  \n",
       "4                [inference parameters, model control]  \n",
       "..                                                 ...  \n",
       "643            [monitoring, usage, cost, token counts]  \n",
       "644  [supported models, regions, token counting, av...  \n",
       "645  [token count, API response, input tokens, outp...  \n",
       "646                      [example, python, boto3, API]  \n",
       "647  [quota increase, limits, service quotas, request]  \n",
       "\n",
       "[648 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9729e120-79bd-40eb-8d73-5b0a86e85d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5829a9bc-de48-4450-b4b8-5fdd248e25d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'service', 'category', 'title', 'content', 'tags'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e629ea3e-9aa5-4c69-b9ca-6eb039a38378",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9193eca-f2d0-47b8-8c1a-e0869a8f01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357b297b-88b3-4866-84e6-cbae907bd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields = ['service', 'category', 'title', 'content'],\n",
    "    keyword_fields = ['tags']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c31e51-e4c5-462a-b65f-49d47710babf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x24b33f75810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625736a1-381e-41d6-87f7-5ba1e10c3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_query = \"temperature in llm. answer in 2 lines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f5d5a59-f0b0-477d-83cc-5a52139d6a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 164,\n",
       "  'service': 'Amazon Bedrock',\n",
       "  'category': 'Prompt engineering concepts',\n",
       "  'title': 'Question-answer, with context',\n",
       "  'content': 'In a question-answer, with context task, the user provides an input text followed by a specific question. The Large Language Model (LLM) is then instructed to answer the question solely based on the information contained within that provided text. Placing the question at the end of the prompt after the context is often beneficial for LLMs on Amazon Bedrock to better focus on the task. Model encouragement and wrapping input text in XML tags (for Anthropic Claude) can further enhance the accuracy of the generated responses.',\n",
       "  'tags': ['question-answer',\n",
       "   'with context',\n",
       "   'information extraction',\n",
       "   'prompting',\n",
       "   'llm tasks']},\n",
       " {'id': 163,\n",
       "  'service': 'Amazon Bedrock',\n",
       "  'category': 'Prompt engineering concepts',\n",
       "  'title': 'Question-answer, without context',\n",
       "  'content': \"In a question-answer, without context task, the Large Language Model (LLM) is required to answer a question solely based on its internal knowledge, without any explicit context or external document provided within the prompt. The prompt typically consists only of the question itself, possibly with model encouragement or constraints. This task assesses the model's ability to retrieve and synthesize information from its training data to generate a relevant response.\",\n",
       "  'tags': ['question-answer',\n",
       "   'no context',\n",
       "   'internal knowledge',\n",
       "   'prompting',\n",
       "   'llm tasks']},\n",
       " {'id': 252,\n",
       "  'service': 'Amazon Bedrock',\n",
       "  'category': 'Model Evaluation',\n",
       "  'title': 'Creating an LLM as a Judge Evaluation Job',\n",
       "  'content': 'To create an LLM as a judge model evaluation job, you submit a request that specifies the models to be evaluated and the chosen judge LLM. This process involves defining the input prompt datasets and the desired evaluation metrics. An IAM service role with appropriate permissions is required, along with S3 bucket configurations for input and output data. This job orchestrates the evaluation by the judge LLM to generate automated performance reports.',\n",
       "  'tags': ['create job', 'llm as judge', 'api', 's3']},\n",
       " {'id': 251,\n",
       "  'service': 'Amazon Bedrock',\n",
       "  'category': 'Model Evaluation',\n",
       "  'title': 'Evaluation Metrics for LLM as a Judge',\n",
       "  'content': 'LLM as a judge model evaluation jobs produce various evaluation metrics to quantify model performance. These metrics are computed by the judge LLM, providing insights into aspects such as accuracy, relevance, coherence, or fluency of the model responses. The specific metrics would be tailored to the evaluation task and the capabilities of the judge LLM. These metrics help users compare and select the most suitable model for their applications.',\n",
       "  'tags': ['evaluation metrics',\n",
       "   'llm as judge',\n",
       "   'performance metrics',\n",
       "   'accuracy']},\n",
       " {'id': 250,\n",
       "  'service': 'Amazon Bedrock',\n",
       "  'category': 'Model Evaluation',\n",
       "  'title': 'Prompt Datasets for LLM as a Judge',\n",
       "  'content': \"Prompt datasets for LLM as a judge model evaluation jobs are essential inputs for the evaluation process. These datasets contain the prompts or user queries that the models under evaluation will respond to. The judge LLM then evaluates these responses against the given prompts, and potentially against 'ground truth' answers or specified criteria, to determine performance metrics. The quality and structure of these datasets significantly influence the accuracy and utility of the LLM-based evaluation.\",\n",
       "  'tags': ['prompt datasets',\n",
       "   'llm as judge',\n",
       "   'evaluation data',\n",
       "   'ground truth']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(temp_query, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a039b22-b835-4e71-9e13-0bf25913afe5",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f2aed5e-3844-4884-89ce-0eb4a511dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c50b5932-4c4b-458a-8d2c-48f1e0f61786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ba74d41-b6bf-4293-b702-0547ee42b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"AWS_BEARER_TOKEN_BEDROCK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eea4a8e8-7071-4f77-bc39-773a18e6845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client =  boto3.client(\n",
    "    service_name = \"bedrock-runtime\",\n",
    "    region_name = \"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4812d3b5-25a6-4dc4-baee-d003b1c6f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"amazon.nova-micro-v1:0\"\n",
    "temp_query = \"bedrock agent use. answer in 4 lines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5be2a363-0958-48a6-a1b0-9d4b9e1f2166",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"role\": \"user\", \"content\": [{\"text\": temp_query}] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba4410d-3be1-42a3-81d4-d669a6eea4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.converse(\n",
    " modelId=model_id,\n",
    " messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8193cebd-ec8a-4055-a329-ec19083ad751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock agents facilitate complex tasks by processing data and making decisions. They utilize machine learning to adapt and improve over time. These agents can automate repetitive processes, enhancing efficiency. Their applications span various fields, from healthcare to finance.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b813ed0-26b6-41ad-9eff-f86208328b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(\"what is prompt engineeing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b4ee3b-8879-4343-ad13-08dabff414cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "                query=query,\n",
    "                filter_dict={},\n",
    "                boost_dict=boost,\n",
    "                num_results=3\n",
    "            )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e015f8fc-0b92-4b7d-9009-d7cf3dafe10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a aws expert. Answer the QUESTION based on the CONTEXT from our aws core service database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "id: {id}\n",
    "service: {service}\n",
    "category: {category}\n",
    "title: {title}\n",
    "content: {content}\n",
    "tags: {tags}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context =\"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a0f38af-dc03-4825-8482-aa03793f2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}] }]\n",
    "\n",
    "    inference_config = {\"temperature\": 0.1, \"topP\": 0.9}\n",
    "\n",
    "    response = client.converse(modelId=model, messages=messages, inferenceConfig=inference_config)\n",
    "    \n",
    "    try:\n",
    "        return response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f202333b-0881-4275-9752-3c868727df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3ffe596-6f12-4a36-bbcc-a105c7148ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost for fine-tuning a model in Amazon Bedrock is not explicitly mentioned in the provided context. However, the context does detail the cost structure for running custom models based on the volume of input and output tokens processed during inference, and the need to purchase Provisioned Throughput. For specific fine-tuning costs, detailed pricing information is available on the Model providers page in the Amazon Bedrock console.\n"
     ]
    }
   ],
   "source": [
    "question = \"how much it cost for fine tunning model? answr in concise way.\"\n",
    "model_id = \"amazon.nova-micro-v1:0\"\n",
    "answer = rag(question, model_id)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae346b3-5869-452b-a15e-40cf23321e15",
   "metadata": {},
   "source": [
    "## ElasticSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66eb88a-06cb-4a40-b237-578a46c164bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4ff7de1-675b-462c-9401-d68995a43ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7e3fb40-9dbe-4182-b133-4d8cffd7ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'bedrock_knowledge_base'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"service\": {\"type\": \"text\"},\n",
    "            \"category\": {\"type\": \"text\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"tags\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"bedrock_knowledge_base\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63c3b83e-4570-49af-9315-e480040be97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'service': 'Amazon Bedrock',\n",
       " 'category': 'Terminology',\n",
       " 'title': 'Foundation model (FM)',\n",
       " 'content': 'An AI model with a large number of parameters and trained on a massive amount of diverse data. A foundation model can generate a variety of responses for a wide range of use cases. Foundation models can generate text or image, and can also convert input into embeddings. Before you can use an Amazon Bedrock foundation model, you must request access.',\n",
       " 'tags': ['foundation model', 'FM', 'AI model']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3664d5c-98da-49b9-aad4-4398281f66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7ce0633-f5c0-4479-b0d9-cf4289a44f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84c526b92b64d748e876e8ee723ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17c4bdf2-8873-4a58-8c27-704093787ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"category^3\", \"title^2\", \"content\", \"tags^3\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"match\": {\n",
    "                        \"service\": \"Amazon Bedrock\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94145050-d405-4606-adf3-7e72702313cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model_id):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model_id)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb2bcfe1-f519-4350-a9ef-92905d271741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost for fine-tuning a model in Amazon Bedrock is not explicitly mentioned in the provided context. The context details the cost of running a custom model based on input and output tokens, provisioned throughput, and optimization strategies, but does not specify the cost associated with fine-tuning. For detailed pricing information, refer to the Model providers page in the Amazon Bedrock console.\n"
     ]
    }
   ],
   "source": [
    "query = \"how much it cost for fine tunning model? answer in concise way.\"\n",
    "model_id = \"amazon.nova-micro-v1:0\"\n",
    "answer = rag(query, model_id)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4817a-b2b0-4f80-a8af-38d0e1b58f19",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caae2e73-c447-4446-aa7c-92401aa82a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv('data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a28bb73-326f-4ea1-a9b4-73c8b0e4f2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the definition of a foundation model i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How can a foundation model generate a variety ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>What types of data can a foundation model conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What is required before using an Amazon Bedroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What are the different use cases for a foundat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question\n",
       "0   0  What is the definition of a foundation model i...\n",
       "1   0  How can a foundation model generate a variety ...\n",
       "2   0  What types of data can a foundation model conv...\n",
       "3   0  What is required before using an Amazon Bedroc...\n",
       "4   0  What are the different use cases for a foundat..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb54607c-cc3b-48b5-8e4b-66435dbe1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a9865c8-94f5-4d41-8a19-3d7017ce493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'question': 'What is the definition of a foundation model in Amazon Bedrock?'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db26b200-feec-4a06-a6fb-6c7bdf7054d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e689f348-554e-49f9-abb6-24f33725bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {\n",
    "        \"category\": 2.0,\n",
    "        \"tags\": 1.5,\n",
    "        \"title\": 1.0 \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95b462c5-18ee-414c-83ed-3f04667bfc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7c7dd6f-1158-451f-892e-870d630404a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bae0803a-6989-4f51-a3a1-cafe1c90655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a9fe29d-b445-414a-a513-c37d5df3ece4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118b7787e3674aec9274ecc51dffcdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.341358024691358, 'mrr': 0.24078287281990976}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff4e5f4f-fe15-4d0e-9148-c08542b8c3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a62a77ed3b49ecae571b7b3f7f028c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5098765432098765, 'mrr': 0.38671859690378224}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febc4f9-716a-4a01-a2e2-791c86dec071",
   "metadata": {},
   "source": [
    "## Finding the best parameters for minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01114409-0a07-4e8e-a3ed-dc8980795740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f534cc2-a44d-4916-9297-95552dec27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf8fbebc-50fb-4123-a4f5-cab542702685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c957d5b2-4a26-4003-8619-4852d5f219d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7380005-f5b8-4d6c-9ea0-fc2009deed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:39,284] A new study created in memory with name: no-name-2b644404-00f7-492f-8e81-4216df585156\n",
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_1048\\1043055660.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  boost[name] = trial.suggest_uniform(name, low, high)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a110efe1940b7967c2219fc7839eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:42,796] Trial 0 finished with value: 0.3883877483128981 and parameters: {'category': 0.749080237694725, 'tags': 1.4260714596148742, 'title': 0.7319939418114051}. Best is trial 0 with value: 0.3883877483128981.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ec983adcf046a8b1d7f6e09bea6d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:46,528] Trial 1 finished with value: 0.3859426910299003 and parameters: {'category': 1.1973169683940732, 'tags': 0.23402796066365478, 'title': 0.15599452033620265}. Best is trial 0 with value: 0.3883877483128981.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c163dff28444c41b24a254de90aa9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:49,487] Trial 2 finished with value: 0.39262857591247413 and parameters: {'category': 0.11616722433639892, 'tags': 1.2992642186624028, 'title': 0.6011150117432088}. Best is trial 2 with value: 0.39262857591247413.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ab2a42a8024bba848d5f88b9462e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:52,597] Trial 3 finished with value: 0.3921869004011861 and parameters: {'category': 1.416145155592091, 'tags': 0.03087674144370367, 'title': 0.9699098521619943}. Best is trial 2 with value: 0.39262857591247413.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20433bea2b304578b899877f883490c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:55,652] Trial 4 finished with value: 0.3874718826924708 and parameters: {'category': 1.6648852816008435, 'tags': 0.31850866601741423, 'title': 0.18182496720710062}. Best is trial 2 with value: 0.39262857591247413.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc06c2fdc841c29cd71e56eff0e825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:47:58,665] Trial 5 finished with value: 0.39083333333333314 and parameters: {'category': 0.36680901970686763, 'tags': 0.4563633644393066, 'title': 0.5247564316322378}. Best is trial 2 with value: 0.39262857591247413.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c9498c1ae34bc6a09d5852a6253048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:01,496] Trial 6 finished with value: 0.3917265933446134 and parameters: {'category': 0.8638900372842315, 'tags': 0.43684371029706287, 'title': 0.6118528947223795}. Best is trial 2 with value: 0.39262857591247413.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddf92b002954403aaa812629f0ac1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:04,292] Trial 7 finished with value: 0.39591780606632054 and parameters: {'category': 0.27898772130408367, 'tags': 0.43821697280282723, 'title': 0.3663618432936917}. Best is trial 7 with value: 0.39591780606632054.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c6346d570b4ccbabef0574b005895f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:07,241] Trial 8 finished with value: 0.3951824054903761 and parameters: {'category': 0.9121399684340719, 'tags': 1.1777639420895203, 'title': 0.19967378215835974}. Best is trial 7 with value: 0.39591780606632054.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f917c7e5654cedbb13b764fe5ead54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:11,248] Trial 9 finished with value: 0.3929911650194664 and parameters: {'category': 1.0284688768272232, 'tags': 0.8886218532930636, 'title': 0.046450412719997725}. Best is trial 7 with value: 0.39591780606632054.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6f88a100b4465f9eba71288b9b17ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:17,550] Trial 10 finished with value: 0.39589102845439184 and parameters: {'category': 0.41523768324303534, 'tags': 0.7099909821820028, 'title': 0.35349387565816887}. Best is trial 7 with value: 0.39591780606632054.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5450dd5f609a4dd5b6b49c5f931ca3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:23,090] Trial 11 finished with value: 0.3986383705133697 and parameters: {'category': 0.4620399792515078, 'tags': 0.7784266882280907, 'title': 0.3670717954717113}. Best is trial 11 with value: 0.3986383705133697.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83b7099be9b4133b3ab932d3432b468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:26,470] Trial 12 finished with value: 0.40414429060904744 and parameters: {'category': 0.026035792562728532, 'tags': 0.7370529066411016, 'title': 0.3577123916785768}. Best is trial 12 with value: 0.40414429060904744.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e673caea0845cea08de11e5951e9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:30,007] Trial 13 finished with value: 0.4095445915435131 and parameters: {'category': 0.007417207619000346, 'tags': 0.877397308352559, 'title': 0.3560912233349938}. Best is trial 13 with value: 0.4095445915435131.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ea73b434594e7aa1cba9100e335949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:32,949] Trial 14 finished with value: 0.41409433393610506 and parameters: {'category': 0.0469671912922755, 'tags': 0.9738221775963493, 'title': 0.4263422836814598}. Best is trial 14 with value: 0.41409433393610506.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de3108b53f34966819845005e0576ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:39,309] Trial 15 finished with value: 0.4150452577725295 and parameters: {'category': 0.6365725002496158, 'tags': 1.034835635024538, 'title': 0.7676259977007911}. Best is trial 15 with value: 0.4150452577725295.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522035c49eb044a3ae067371483101b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:43,377] Trial 16 finished with value: 0.4160535955272788 and parameters: {'category': 0.6630897845793549, 'tags': 1.0497103944025048, 'title': 0.8297184613542987}. Best is trial 16 with value: 0.4160535955272788.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4730c6742ead4ec69925c41ee1823bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:46,759] Trial 17 finished with value: 0.41706963340891806 and parameters: {'category': 0.6435343552005294, 'tags': 1.1113941097838445, 'title': 0.8825505476032763}. Best is trial 17 with value: 0.41706963340891806.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80aa99fb099346f199a6b3c71262293a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:49,538] Trial 18 finished with value: 0.41660073497622035 and parameters: {'category': 1.2552858905118995, 'tags': 1.153034814070398, 'title': 0.9913504578900646}. Best is trial 17 with value: 0.41706963340891806.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713aa537038846878025bc61993cd1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:48:52,443] Trial 19 finished with value: 0.41443618987034925 and parameters: {'category': 1.9920330634948704, 'tags': 1.4674120420139587, 'title': 0.9918275293482719}. Best is trial 17 with value: 0.41706963340891806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna best MRR: 0.41706963340891806\n",
      "Optuna best boost: {'category': 0.6435343552005294, 'tags': 1.1113941097838445, 'title': 0.8825505476032763}\n"
     ]
    }
   ],
   "source": [
    "SEED = 42  # use only this seed as requested\n",
    "\n",
    "param_ranges = {\n",
    "    'category': (0.0, 2.0),\n",
    "    'tags': (0.0, 1.5),\n",
    "    'title': (0.0, 1.0),\n",
    "}\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    # Suggest floats in the same ranges as your original random search\n",
    "    boost = {}\n",
    "    for name, (low, high) in param_ranges.items():\n",
    "        boost[name] = trial.suggest_uniform(name, low, high)\n",
    "\n",
    "    # keep your evaluation plumbing unchanged\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    # maximize MRR\n",
    "    return results['mrr']\n",
    "\n",
    "def run_optuna_search(n_trials=20):\n",
    "    sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(optuna_objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "\n",
    "    # Prepare a boost dict identical to what your old code returned\n",
    "    best_boost = {k: float(v) for k, v in best_params.items()}\n",
    "\n",
    "    print(\"Optuna best MRR:\", best_value)\n",
    "    print(\"Optuna best boost:\", best_boost)\n",
    "\n",
    "    return best_boost, best_value, study\n",
    "\n",
    "# Example call (keeps n_trials same as your previous n_iterations)\n",
    "best_boost, best_value, study = run_optuna_search(n_trials=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f4aa4e4-fa65-4290-a327-e7b1743bae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {\n",
    "        \"category\": 0.20,\n",
    "        \"tags\": 0.11,\n",
    "        \"title\": 0.92\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41301beb-5bf4-4a6e-beb9-06d4194a4e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ded2f37a6f4513ae4f3ff0c136c84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6293002915451895, 'mrr': 0.4619597737054016}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94e23c-1ff5-48ad-ad30-50cb2a413b00",
   "metadata": {},
   "source": [
    "## Finding the best parameters for elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aed81b04-a3e3-4b9e-8223-ecc4d63962b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb99abe6-9a54-46a5-a509-350c92727d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d44bf2d-34a3-4657-aa14-d9efdea97691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {'category': 3.0, 'title': 2.0, 'content': 1.0, 'tags': 3.0}\n",
    "\n",
    "    fields = []\n",
    "    for field, weight in boost.items():\n",
    "        if weight > 0:\n",
    "            fields.append(f\"{field}^{weight}\")\n",
    "        else:\n",
    "            fields.append(field)\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": fields,\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"match\": {\n",
    "                        \"service\": \"Amazon Bedrock\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4eb2d12d-2ec5-437c-bc6b-dfb608c4a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "169ac0d5-43d1-466d-bf27-459167c84c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:58:53,388] A new study created in memory with name: no-name-852c8c55-482a-4273-8936-0fc787b4f7d2\n",
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_1048\\1646728372.py:14: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  boost[name] = trial.suggest_uniform(name, low, high)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfe85605b0d434990271db19bf34fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:00,580] Trial 0 finished with value: 0.46388084975369565 and parameters: {'category': 1.49816047538945, 'title': 3.8028572256396647, 'content': 2.9279757672456204, 'tags': 2.3946339367881464}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718a3829b1424da3bf85d3a8851d425a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:07,486] Trial 1 finished with value: 0.4630208754890068 and parameters: {'category': 0.6240745617697461, 'title': 0.6239780813448106, 'content': 0.23233444867279784, 'tags': 3.4647045830997407}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684fdfeceb774ea2a590dfddd9f2cb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:14,409] Trial 2 finished with value: 0.46180782787975616 and parameters: {'category': 2.404460046972835, 'title': 2.832290311184182, 'content': 0.08233797718320979, 'tags': 3.8796394086479773}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb676c5b7a0e47f2a63f9aad4c6fad93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:21,412] Trial 3 finished with value: 0.4598315951725052 and parameters: {'category': 3.329770563201687, 'title': 0.8493564427131046, 'content': 0.7272998688284025, 'tags': 0.7336180394137353}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10dd02fcaac465fa892d9b1ce9e6e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:28,436] Trial 4 finished with value: 0.4619715644409948 and parameters: {'category': 1.216968971838151, 'title': 2.0990257265289514, 'content': 1.727780074568463, 'tags': 1.1649165607921677}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b66811ac9a41468d0fe53069d9cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:35,301] Trial 5 finished with value: 0.46375925571301013 and parameters: {'category': 2.447411578889518, 'title': 0.5579754426081673, 'content': 1.1685785941408726, 'tags': 1.4654473731747668}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3757b60bb5ff40baadbf3807c13c1878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:42,652] Trial 6 finished with value: 0.4627373078861184 and parameters: {'category': 1.8242799368681437, 'title': 3.1407038455720544, 'content': 0.7986951286334389, 'tags': 2.0569377536544464}. Best is trial 0 with value: 0.46388084975369565.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbfd739319240b595fee435dfcc2a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:49,830] Trial 7 finished with value: 0.4647076650503554 and parameters: {'category': 2.36965827544817, 'title': 0.1858016508799909, 'content': 2.4301794076057535, 'tags': 0.6820964947491661}. Best is trial 7 with value: 0.4647076650503554.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b68e0f2cfa41b6aa26c4223df48cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 16:59:57,164] Trial 8 finished with value: 0.4673768102601876 and parameters: {'category': 0.26020637194111806, 'title': 3.795542149013333, 'content': 3.8625281322982374, 'tags': 3.2335893924658445}. Best is trial 8 with value: 0.4673768102601876.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ae0dfab445400eafeb4924179b6bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:03,983] Trial 9 finished with value: 0.46923800436205126 and parameters: {'category': 1.2184550766934827, 'title': 0.3906884560255355, 'content': 2.7369321060486276, 'tags': 1.7606099749584052}. Best is trial 9 with value: 0.46923800436205126.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630f1664716245049d2c645b4ee8e570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:10,931] Trial 10 finished with value: 0.47105243479301384 and parameters: {'category': 3.7805461769215456, 'title': 1.4549106944865244, 'content': 3.4138884150769346, 'tags': 0.07184750245927995}. Best is trial 10 with value: 0.47105243479301384.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026c2d475a0142db9edb1add18795bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:17,796] Trial 11 finished with value: 0.47282184213635947 and parameters: {'category': 3.743031258080954, 'title': 1.3754701764520596, 'content': 3.494642402901741, 'tags': 0.0978537724175319}. Best is trial 11 with value: 0.47282184213635947.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d09565dadea4bc1834cfa39d2a27aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:24,648] Trial 12 finished with value: 0.4745478816526624 and parameters: {'category': 3.9253051520013473, 'title': 1.4669605055263262, 'content': 3.975038528143521, 'tags': 0.0193091799165684}. Best is trial 12 with value: 0.4745478816526624.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d82cc0087d24f71be1e3376b5b695ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:31,449] Trial 13 finished with value: 0.4762321284445995 and parameters: {'category': 3.894857815269665, 'title': 1.545578232165592, 'content': 3.975269225366084, 'tags': 0.0426745558849756}. Best is trial 13 with value: 0.4762321284445995.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad0415147ac41a6b707130e63239ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:38,565] Trial 14 finished with value: 0.47787608225108363 and parameters: {'category': 3.0330095954911385, 'title': 2.0116409406313647, 'content': 3.8673100466218453, 'tags': 0.5763650708863748}. Best is trial 14 with value: 0.47787608225108363.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53242acde73a49989a9fcd694b9bb62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:45,319] Trial 15 finished with value: 0.47952057300461703 and parameters: {'category': 3.001542641636441, 'title': 2.1780809075385528, 'content': 3.3362927917656244, 'tags': 0.799602586720596}. Best is trial 15 with value: 0.47952057300461703.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec68b090c6cf49e4a1da12af486c2af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:52,175] Trial 16 finished with value: 0.4812960336003575 and parameters: {'category': 3.0776966655866285, 'title': 2.34771477449443, 'content': 3.170568439631311, 'tags': 0.9085560466035147}. Best is trial 16 with value: 0.4812960336003575.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86124077cfce4ee29c4cd391462ce78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:00:59,606] Trial 17 finished with value: 0.4830978499945024 and parameters: {'category': 2.785225730790395, 'title': 2.6297953705047887, 'content': 2.2574800507322546, 'tags': 1.153828334261493}. Best is trial 17 with value: 0.4830978499945024.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089fd6d883cb4b94a250c95874d2df05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:01:06,555] Trial 18 finished with value: 0.48408798108284506 and parameters: {'category': 2.9514209580170374, 'title': 2.686051220520369, 'content': 1.9878776004546268, 'tags': 2.578694741072342}. Best is trial 18 with value: 0.48408798108284506.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dadd7ce3d2470195b6e0156dbb11ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-15 17:01:13,310] Trial 19 finished with value: 0.4845892454047088 and parameters: {'category': 2.667831003311455, 'title': 2.8137511819215306, 'content': 1.848459033604512, 'tags': 2.6123431320671635}. Best is trial 19 with value: 0.4845892454047088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna best MRR: 0.4845892454047088\n",
      "Optuna best boost: {'category': 2.667831003311455, 'title': 2.8137511819215306, 'content': 1.848459033604512, 'tags': 2.6123431320671635}\n"
     ]
    }
   ],
   "source": [
    "SEED = 42  # use only this seed as requested\n",
    "\n",
    "param_ranges = {\n",
    "    'category': (0.0, 4.0),   \n",
    "    'title': (0.0, 4.0),        \n",
    "    'content': (0.0, 4.0),     \n",
    "    'tags': (0.0, 4.0),\n",
    "}\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    # Suggest floats in the same ranges as your original random search\n",
    "    boost = {}\n",
    "    for name, (low, high) in param_ranges.items():\n",
    "        boost[name] = trial.suggest_uniform(name, low, high)\n",
    "\n",
    "    # keep your evaluation plumbing unchanged\n",
    "    def search_function(q):\n",
    "        return elastic_search(q['question'], boost)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    # maximize MRR\n",
    "    return results['mrr']\n",
    "\n",
    "def run_optuna_search(n_trials=20):\n",
    "    sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(optuna_objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "\n",
    "    # Prepare a boost dict identical to what your old code returned\n",
    "    best_boost = {k: float(v) for k, v in best_params.items()}\n",
    "\n",
    "    print(\"Optuna best MRR:\", best_value)\n",
    "    print(\"Optuna best boost:\", best_boost)\n",
    "\n",
    "    return best_boost, best_value, study\n",
    "\n",
    "# Example call (keeps n_trials same as your previous n_iterations)\n",
    "best_boost, best_value, study = run_optuna_search(n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3297ec7-52f3-41df-97e3-422de94e7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"category^2.6\", \"title^2.8\", \"content^1.8\", \"tags^2.6\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"match\": {\n",
    "                        \"service\": \"Amazon Bedrock\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "767f5e1a-3dd9-4ac5-b2fc-7fdf3ded5317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a471d37747943debb4cfdda690e67b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6721374045801527, 'mrr': 0.515851849327514}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search(q['question']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
